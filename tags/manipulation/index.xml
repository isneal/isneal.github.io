<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Manipulation on Neal Pang</title><link>https://isneal.github.io/tags/manipulation/</link><description>Recent content in Manipulation on Neal Pang</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Wed, 29 Oct 2025 12:00:00 +0800</lastBuildDate><atom:link href="https://isneal.github.io/tags/manipulation/index.xml" rel="self" type="application/rss+xml"/><item><title>Diffusion Policy for Robot Manipulation</title><link>https://isneal.github.io/p/dp/</link><pubDate>Wed, 29 Oct 2025 12:00:00 +0800</pubDate><guid>https://isneal.github.io/p/dp/</guid><description>&lt;h2 id="大模型多模态信息融合的方法"&gt;大模型多模态信息融合的方法
&lt;/h2&gt;&lt;h3 id="cnn-based发源自视觉推理视觉问答"&gt;CNN-based（发源自视觉推理/视觉问答）
&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;问题&lt;/p&gt;
&lt;p&gt;实现文本条件下的图像输出&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;方法&lt;/p&gt;
&lt;p&gt;FiLM (Feature-wise Linear Modulation)&lt;/p&gt;
&lt;p&gt;条件编码器（文本、图像等）经过FIlM，产生仿射变换的参数。仿射变换的参数在每个resnet的block中都可以加入，相当于做了一次 attention，可以理解为拿文本信息去attention视觉的内容，而且是从每级的feature上面都是如此。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id="transformer-based"&gt;Transformer-based
&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;常规方法&lt;/p&gt;
&lt;p&gt;Transformer架构：文本作为值多头注意到图像上&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;CLIP&lt;/p&gt;
&lt;p&gt;图像条件下的文本（类别）输出&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id="创新点立足点贡献"&gt;创新点/立足点/贡献
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;闭环动作生成？？预测与执行的关系+优化推理速度，何为闭环？？&lt;/li&gt;
&lt;li&gt;状态动作条件概率分布 | 联合分布——条件分布&lt;/li&gt;
&lt;li&gt;transformer架构的diffusion policy | cnn diffusion —— transformer diffusion&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id="前序工作"&gt;前序工作
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;CNN-based diffusion model for planning&lt;/p&gt;
&lt;p&gt;Planning with Diffusion for Flexible Behavior Synthesis&lt;/p&gt;
&lt;p&gt;&lt;a class="link" href="https://jannerm.github.io/" target="_blank" rel="noopener"
&gt;Michael Janner&lt;/a&gt;&lt;em&gt;, &lt;a class="link" href="https://yilundu.github.io/" target="_blank" rel="noopener"
&gt;Yilun Du&lt;/a&gt;&lt;/em&gt;, &lt;a class="link" href="https://cocosci.mit.edu/josh" target="_blank" rel="noopener"
&gt;Joshua Tenenbaum&lt;/a&gt;, and &lt;a class="link" href="https://people.eecs.berkeley.edu/~svlevine/" target="_blank" rel="noopener"
&gt;Sergey Levine&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Behavior transformer w/o diffusion&lt;/p&gt;
&lt;p&gt;Behavior Transformers: Cloning k modes with one stone&lt;/p&gt;
&lt;p&gt;&lt;a class="link" href="https://mahis.life/" target="_blank" rel="noopener"
&gt;Nur Muhammad (Mahi) Shafiullah,&lt;/a&gt; &lt;a class="link" href="https://jeffcui.com/" target="_blank" rel="noopener"
&gt;Zichen Jeff Cui,&lt;/a&gt; &lt;a class="link" href="https://artys.page/" target="_blank" rel="noopener"
&gt;Ariuntaya Altanzaya,&lt;/a&gt; &lt;a class="link" href="https://lerrelpinto.com/" target="_blank" rel="noopener"
&gt;Lerrel Pinto&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;引申学习&lt;/p&gt;
&lt;p&gt;&lt;a class="link" href="https://arxiv.org/pdf/1706.03762" target="_blank" rel="noopener"
&gt;Attention Is All You Need 2017&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class="link" href="https://arxiv.org/pdf/2010.11929" target="_blank" rel="noopener"
&gt;ViT 2020&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Diffusion Model &lt;a class="link" href="https://arxiv.org/pdf/1503.03585" target="_blank" rel="noopener"
&gt;[1-2015]&lt;/a&gt; &lt;a class="link" href="https://arxiv.org/pdf/1907.05600" target="_blank" rel="noopener"
&gt;[2-2019]&lt;/a&gt; &lt;a class="link" href="https://arxiv.org/pdf/2006.11239" target="_blank" rel="noopener"
&gt;[3-DDPM-2020]&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class="link" href="https://arxiv.org/pdf/2212.09748" target="_blank" rel="noopener"
&gt;Diffusion Transformer 2023&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class="link" href="https://arxiv.org/pdf/2410.07864" target="_blank" rel="noopener"
&gt;RDT 2024&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class="link" href="https://arxiv.org/pdf/2304.13705" target="_blank" rel="noopener"
&gt;ACT 2023&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Flow Matching &lt;a class="link" href="https://arxiv.org/pdf/2409.01083v1" target="_blank" rel="noopener"
&gt;[1-2024]&lt;/a&gt; &lt;a class="link" href="https://arxiv.org/pdf/2410.24164" target="_blank" rel="noopener"
&gt;[2-pi0-2024]&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;</description></item></channel></rss>