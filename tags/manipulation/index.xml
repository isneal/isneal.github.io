<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Manipulation on Neal</title><link>https://isneal.github.io/tags/manipulation/</link><description>Recent content in Manipulation on Neal</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Sun, 02 Nov 2025 12:00:00 +0800</lastBuildDate><atom:link href="https://isneal.github.io/tags/manipulation/index.xml" rel="self" type="application/rss+xml"/><item><title>Compliance Control for Robot Manipulation</title><link>https://isneal.github.io/p/compliance/</link><pubDate>Sun, 02 Nov 2025 12:00:00 +0800</pubDate><guid>https://isneal.github.io/p/compliance/</guid><description>&lt;h2 id="impedance-control"&gt;Impedance Control
&lt;/h2&gt;&lt;h2 id="admittance-control"&gt;Admittance Control
&lt;/h2&gt;</description></item><item><title>Research Proposal</title><link>https://isneal.github.io/p/research-proposal/</link><pubDate>Sun, 02 Nov 2025 12:00:00 +0800</pubDate><guid>https://isneal.github.io/p/research-proposal/</guid><description>&lt;blockquote&gt;
&lt;p&gt;Huazhe Xu 开组会讨论内容&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id="robot-learning方法-通用框架和基本方法"&gt;robot learning方法 通用框架和基本方法
&lt;/h2&gt;&lt;p&gt;IL,&lt;/p&gt;
&lt;p&gt;RL,&lt;/p&gt;
&lt;p&gt;IL+RL&lt;/p&gt;
&lt;p&gt;sim2real&lt;/p&gt;
&lt;h2 id="研究重点对比"&gt;研究重点对比
&lt;/h2&gt;&lt;h2 id="科学问题"&gt;科学问题
&lt;/h2&gt;&lt;p&gt;双臂协作？&lt;/p&gt;
&lt;p&gt;人与机器人协作？&lt;/p&gt;
&lt;p&gt;本体视觉感知+全身控制&lt;/p&gt;
&lt;h2 id="技术路线"&gt;技术路线
&lt;/h2&gt;&lt;h3 id="bimanual-manipulation"&gt;Bimanual Manipulation
&lt;/h3&gt;&lt;p&gt;Diffusion Policy&lt;/p&gt;
&lt;p&gt;LfD&lt;/p&gt;
&lt;p&gt;VLA (LBM | RDT) | 综述&lt;/p&gt;
&lt;p&gt;World Model | 综述&lt;/p&gt;
&lt;p&gt;HIL-SERL (RL)&lt;/p&gt;
&lt;h3 id="low-cost"&gt;Low-Cost
&lt;/h3&gt;&lt;p&gt;Hardware Software Control Framework&lt;/p&gt;
&lt;p&gt;Mobile Manipulation&lt;/p&gt;
&lt;p&gt;研究重点在哪？&lt;/p&gt;
&lt;h3 id="legged"&gt;Legged
&lt;/h3&gt;&lt;p&gt;ABS&lt;/p&gt;
&lt;p&gt;OCS2&lt;/p&gt;
&lt;p&gt;robot_lab&lt;/p&gt;
&lt;p&gt;rl_sar&lt;/p&gt;
&lt;h3 id="humanoid"&gt;Humanoid
&lt;/h3&gt;&lt;p&gt;robot_lab&lt;/p&gt;
&lt;p&gt;iDP3&lt;/p&gt;
&lt;p&gt;OKAMI&lt;/p&gt;
&lt;p&gt;loco-manipulation&lt;/p&gt;
&lt;p&gt;vision-based&lt;/p&gt;
&lt;h2 id="isaac-lab-例程"&gt;Isaac Lab 例程
&lt;/h2&gt;&lt;h2 id="ama"&gt;AMA
&lt;/h2&gt;&lt;p&gt;Tianxing, Yitang, Guanya, Huazhe&lt;/p&gt;</description></item><item><title>Diffusion Policy for Robot Manipulation</title><link>https://isneal.github.io/p/dp/</link><pubDate>Wed, 29 Oct 2025 12:00:00 +0800</pubDate><guid>https://isneal.github.io/p/dp/</guid><description>&lt;h2 id="大模型多模态信息融合的方法"&gt;大模型多模态信息融合的方法
&lt;/h2&gt;&lt;h3 id="cnn-based发源自视觉推理视觉问答"&gt;CNN-based（发源自视觉推理/视觉问答）
&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;问题&lt;/p&gt;
&lt;p&gt;实现文本条件下的图像输出&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;方法&lt;/p&gt;
&lt;p&gt;FiLM (Feature-wise Linear Modulation)&lt;/p&gt;
&lt;p&gt;条件编码器（文本、图像等）经过FIlM，产生仿射变换的参数。仿射变换的参数在每个resnet的block中都可以加入，相当于做了一次 attention，可以理解为拿文本信息去attention视觉的内容，而且是从每级的feature上面都是如此。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id="transformer-based"&gt;Transformer-based
&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;常规方法&lt;/p&gt;
&lt;p&gt;Transformer架构：文本作为值多头注意到图像上&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;CLIP&lt;/p&gt;
&lt;p&gt;图像条件下的文本（类别）输出&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id="创新点立足点贡献"&gt;创新点/立足点/贡献
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;闭环动作生成？？预测与执行的关系+优化推理速度，何为闭环？？&lt;/li&gt;
&lt;li&gt;状态动作条件概率分布 | 联合分布——条件分布&lt;/li&gt;
&lt;li&gt;transformer架构的diffusion policy | cnn diffusion —— transformer diffusion&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id="前序工作"&gt;前序工作
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;CNN-based diffusion model for planning&lt;/p&gt;
&lt;p&gt;Planning with Diffusion for Flexible Behavior Synthesis&lt;/p&gt;
&lt;p&gt;&lt;a class="link" href="https://jannerm.github.io/" target="_blank" rel="noopener"
&gt;Michael Janner&lt;/a&gt;&lt;em&gt;, &lt;a class="link" href="https://yilundu.github.io/" target="_blank" rel="noopener"
&gt;Yilun Du&lt;/a&gt;&lt;/em&gt;, &lt;a class="link" href="https://cocosci.mit.edu/josh" target="_blank" rel="noopener"
&gt;Joshua Tenenbaum&lt;/a&gt;, and &lt;a class="link" href="https://people.eecs.berkeley.edu/~svlevine/" target="_blank" rel="noopener"
&gt;Sergey Levine&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Behavior transformer w/o diffusion&lt;/p&gt;
&lt;p&gt;Behavior Transformers: Cloning k modes with one stone&lt;/p&gt;
&lt;p&gt;&lt;a class="link" href="https://mahis.life/" target="_blank" rel="noopener"
&gt;Nur Muhammad (Mahi) Shafiullah,&lt;/a&gt; &lt;a class="link" href="https://jeffcui.com/" target="_blank" rel="noopener"
&gt;Zichen Jeff Cui,&lt;/a&gt; &lt;a class="link" href="https://artys.page/" target="_blank" rel="noopener"
&gt;Ariuntaya Altanzaya,&lt;/a&gt; &lt;a class="link" href="https://lerrelpinto.com/" target="_blank" rel="noopener"
&gt;Lerrel Pinto&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;引申学习&lt;/p&gt;
&lt;p&gt;&lt;a class="link" href="https://arxiv.org/pdf/1706.03762" target="_blank" rel="noopener"
&gt;Attention Is All You Need 2017&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class="link" href="https://arxiv.org/pdf/2010.11929" target="_blank" rel="noopener"
&gt;ViT 2020&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Diffusion Model &lt;a class="link" href="https://arxiv.org/pdf/1503.03585" target="_blank" rel="noopener"
&gt;[1-2015]&lt;/a&gt; &lt;a class="link" href="https://arxiv.org/pdf/1907.05600" target="_blank" rel="noopener"
&gt;[2-2019]&lt;/a&gt; &lt;a class="link" href="https://arxiv.org/pdf/2006.11239" target="_blank" rel="noopener"
&gt;[3-DDPM-2020]&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class="link" href="https://arxiv.org/pdf/2212.09748" target="_blank" rel="noopener"
&gt;Diffusion Transformer 2023&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class="link" href="https://arxiv.org/pdf/2410.07864" target="_blank" rel="noopener"
&gt;RDT 2024&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class="link" href="https://arxiv.org/pdf/2304.13705" target="_blank" rel="noopener"
&gt;ACT 2023&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Flow Matching &lt;a class="link" href="https://arxiv.org/pdf/2409.01083v1" target="_blank" rel="noopener"
&gt;[1-2024]&lt;/a&gt; &lt;a class="link" href="https://arxiv.org/pdf/2410.24164" target="_blank" rel="noopener"
&gt;[2-pi0-2024]&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;</description></item></channel></rss>